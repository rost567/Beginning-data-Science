{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "235a3efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edf84b1",
   "metadata": {},
   "source": [
    "# Connecting Dots with Regression Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1c20b2",
   "metadata": {},
   "source": [
    "1. What is the likelihood that a customer will buy a second product from your website if they bought their fisrt more than 6 months ago?\n",
    "2. Trend line is a common feature of many business analyses.\n",
    "3. How much do purchases increase when ads are shown more often on a homepage?\n",
    "<br>\n",
    "\n",
    "These sort of questions can be answered by drawing a line, **termed Regression**, representing the average change in our response as we vary the input **based in historical data and using this to extrapolate the response for future data**.<br>\n",
    "That means where we only know the input but no the output yet.\n",
    "<br>\n",
    "Calculating the regression based on: \n",
    "- the hypothesis that our observations are scatterred around the true relationship between the 2 variables.\n",
    "- And on average future observations will regress (approach) the trend line between input and output.\n",
    "<br>\n",
    "\n",
    "**Complexitites in the analysis:**   \n",
    "1. The relationship we fit usually involve not one, but several inputs. So two dimensional line is not an option, instead, to represent the multi-variate relationship, we need more advanced methos to calculate the line trend in a hight-dimensional space.  \n",
    "2. The line trend could be a line, a curve, a wave, or even complex patterns. \n",
    "3. SOmetimes we need to decide which variables we are going to use, which ones are relevant for the problem at hand.\n",
    "4. Determine carefully not just the trend that best fits the data we have, but also, generalizes best to new data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c0f662",
   "metadata": {},
   "source": [
    "## Linear Regression OLS\n",
    "$ y = X\\beta$\n",
    "- $y =$ vector of n responses, is a linear combination of the input of $x$.\n",
    "- $x =$ vector of the input variable also length n, represent a set of input variables, $x$ is a matrix of n rows/observation and m columns/features.\n",
    "- $\\beta$ = slope response (how much the response $y$ increases for each 1-unit increase in the value of $x$). Is a vector set of slopes or coefficients which, when multiplied by the features, give the output.  \n",
    "<br>\n",
    "\n",
    "**What we do not know?**<br>\n",
    "We have to assume that the response incorporates a while noise error term $\\epsilon$.<br>\n",
    "This $\\epsilon$ is a normal distribution with mean $0$ and a constant variance for all data points.<br>\n",
    "To solve for the coefficients $\\beta$ in this model:\n",
    "<br>\n",
    "\n",
    "> **Assumptions:**\n",
    "> - The error term $\\epsilon$ should have constant residual variance, meaning the fit shpuld have constant residual variance.\n",
    "> - The residual, which is the difference between the fitted and actual response, $y$ is assumed to have constants variance ove the range of its values, **if it is not the case, i.e if smaller values of $y$ have smallers errors than larger values, then it suggest we are not appropriately incorporating a source of error in our model**\n",
    "> - The explanation is because the only variation left after we account for the predictors $X$ should be the error term $\\delta$, and it have to have constant variance.\n",
    "> - The residuals are assumed to be un-correlated based on the predictors $X$. This is important because we are trying to model a line between the average of the response data points at each predictor value. **Would be accurate if we assume that the residual error $\\epsilon$ is randomly distributed about $0$**.\n",
    "> - The predictors are assumed not to be collinear, **correlated with one other**. If that happens they cancel each other out when we mae a linear combination of each other matrix $X$. Because in the derivation of $\\beta$, to calculate the coefficients we need to take the inverse, so if columns in the matrix exactly cancel each other out, then the matrix  is reank **deficient** and has no inverse, recall that **if a matrix is full rank, its columns(rows) cannot be represented by a linear combination of the other columns(rows)**. Ranks deficient does not have an inverse.\n",
    "<br>\n",
    "\n",
    "So why does OLS formula for $\\beta$ represent the best estimate of the coefficients: Because is that this value minimizes the squared error.  \n",
    "The **Gaus Markov Theorem, states that the OLS stimate is the Best Linear Unbiased Estimator (BLUE) of the coefficients $\\beta$**. We assume we an error that deviates form the real values, so this BLUE is then the set of coefficients $\\beta$ that have the smallest mean error from the real values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00190c96",
   "metadata": {},
   "source": [
    "**Example**<br>\n",
    "The task is to predict the popularity using these other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f1423da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url   timedelta  \\\n",
       "0  http://mashable.com/2013/01/07/amazon-instant-...       731.0   \n",
       "1  http://mashable.com/2013/01/07/ap-samsung-spon...       731.0   \n",
       "2  http://mashable.com/2013/01/07/apple-40-billio...       731.0   \n",
       "3  http://mashable.com/2013/01/07/astronaut-notre...       731.0   \n",
       "4   http://mashable.com/2013/01/07/att-u-verse-apps/       731.0   \n",
       "\n",
       "    n_tokens_title   n_tokens_content   n_unique_tokens   n_non_stop_words  \\\n",
       "0             12.0              219.0          0.663594                1.0   \n",
       "1              9.0              255.0          0.604743                1.0   \n",
       "2              9.0              211.0          0.575130                1.0   \n",
       "3              9.0              531.0          0.503788                1.0   \n",
       "4             13.0             1072.0          0.415646                1.0   \n",
       "\n",
       "    n_non_stop_unique_tokens   num_hrefs   num_self_hrefs   num_imgs  ...  \\\n",
       "0                   0.815385         4.0              2.0        1.0  ...   \n",
       "1                   0.791946         3.0              1.0        1.0  ...   \n",
       "2                   0.663866         3.0              1.0        1.0  ...   \n",
       "3                   0.665635         9.0              0.0        1.0  ...   \n",
       "4                   0.540890        19.0             19.0       20.0  ...   \n",
       "\n",
       "    min_positive_polarity   max_positive_polarity   avg_negative_polarity  \\\n",
       "0                0.100000                     0.7               -0.350000   \n",
       "1                0.033333                     0.7               -0.118750   \n",
       "2                0.100000                     1.0               -0.466667   \n",
       "3                0.136364                     0.8               -0.369697   \n",
       "4                0.033333                     1.0               -0.220192   \n",
       "\n",
       "    min_negative_polarity   max_negative_polarity   title_subjectivity  \\\n",
       "0                  -0.600               -0.200000             0.500000   \n",
       "1                  -0.125               -0.100000             0.000000   \n",
       "2                  -0.800               -0.133333             0.000000   \n",
       "3                  -0.600               -0.166667             0.000000   \n",
       "4                  -0.500               -0.050000             0.454545   \n",
       "\n",
       "    title_sentiment_polarity   abs_title_subjectivity  \\\n",
       "0                  -0.187500                 0.000000   \n",
       "1                   0.000000                 0.500000   \n",
       "2                   0.000000                 0.500000   \n",
       "3                   0.000000                 0.500000   \n",
       "4                   0.136364                 0.045455   \n",
       "\n",
       "    abs_title_sentiment_polarity   shares  \n",
       "0                       0.187500      593  \n",
       "1                       0.000000      711  \n",
       "2                       0.000000     1500  \n",
       "3                       0.000000     1200  \n",
       "4                       0.136364      505  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv(\"https://raw.githubusercontent.com/PacktPublishing/Python-Advanced-Predictive-Analytics/master/Module%202/MasteringPredictiveAnalyticswithPython_Code/B04881_04_code/OnlineNewsPopularity.csv\")\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6ea36042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url                               object\n",
       " timedelta                       float64\n",
       " n_tokens_title                  float64\n",
       " n_tokens_content                float64\n",
       " n_unique_tokens                 float64\n",
       "                                  ...   \n",
       " title_subjectivity              float64\n",
       " title_sentiment_polarity        float64\n",
       " abs_title_subjectivity          float64\n",
       " abs_title_sentiment_polarity    float64\n",
       " shares                            int64\n",
       "Length: 61, dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#news.columns\n",
    "news.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a3104d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>354.530471</td>\n",
       "      <td>10.398749</td>\n",
       "      <td>546.514731</td>\n",
       "      <td>0.548216</td>\n",
       "      <td>0.996469</td>\n",
       "      <td>0.689175</td>\n",
       "      <td>10.883690</td>\n",
       "      <td>3.293638</td>\n",
       "      <td>4.544143</td>\n",
       "      <td>1.249874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095446</td>\n",
       "      <td>0.756728</td>\n",
       "      <td>-0.259524</td>\n",
       "      <td>-0.521944</td>\n",
       "      <td>-0.107500</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.071425</td>\n",
       "      <td>0.341843</td>\n",
       "      <td>0.156064</td>\n",
       "      <td>3395.380184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>214.163767</td>\n",
       "      <td>2.114037</td>\n",
       "      <td>471.107508</td>\n",
       "      <td>3.520708</td>\n",
       "      <td>5.231231</td>\n",
       "      <td>3.264816</td>\n",
       "      <td>11.332017</td>\n",
       "      <td>3.855141</td>\n",
       "      <td>8.309434</td>\n",
       "      <td>4.107855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071315</td>\n",
       "      <td>0.247786</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>0.290290</td>\n",
       "      <td>0.095373</td>\n",
       "      <td>0.324247</td>\n",
       "      <td>0.265450</td>\n",
       "      <td>0.188791</td>\n",
       "      <td>0.226294</td>\n",
       "      <td>11626.950749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>164.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>0.470870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625739</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.328383</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>946.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>339.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>0.539226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.253333</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>542.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>716.000000</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.754630</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.186905</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>731.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>8474.000000</td>\n",
       "      <td>701.000000</td>\n",
       "      <td>1042.000000</td>\n",
       "      <td>650.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "count  39644.000000    39644.000000      39644.000000     39644.000000   \n",
       "mean     354.530471       10.398749        546.514731         0.548216   \n",
       "std      214.163767        2.114037        471.107508         3.520708   \n",
       "min        8.000000        2.000000          0.000000         0.000000   \n",
       "25%      164.000000        9.000000        246.000000         0.470870   \n",
       "50%      339.000000       10.000000        409.000000         0.539226   \n",
       "75%      542.000000       12.000000        716.000000         0.608696   \n",
       "max      731.000000       23.000000       8474.000000       701.000000   \n",
       "\n",
       "       n_non_stop_words  n_non_stop_unique_tokens     num_hrefs  \\\n",
       "count      39644.000000              39644.000000  39644.000000   \n",
       "mean           0.996469                  0.689175     10.883690   \n",
       "std            5.231231                  3.264816     11.332017   \n",
       "min            0.000000                  0.000000      0.000000   \n",
       "25%            1.000000                  0.625739      4.000000   \n",
       "50%            1.000000                  0.690476      8.000000   \n",
       "75%            1.000000                  0.754630     14.000000   \n",
       "max         1042.000000                650.000000    304.000000   \n",
       "\n",
       "       num_self_hrefs      num_imgs    num_videos  ...  min_positive_polarity  \\\n",
       "count    39644.000000  39644.000000  39644.000000  ...           39644.000000   \n",
       "mean         3.293638      4.544143      1.249874  ...               0.095446   \n",
       "std          3.855141      8.309434      4.107855  ...               0.071315   \n",
       "min          0.000000      0.000000      0.000000  ...               0.000000   \n",
       "25%          1.000000      1.000000      0.000000  ...               0.050000   \n",
       "50%          3.000000      1.000000      0.000000  ...               0.100000   \n",
       "75%          4.000000      4.000000      1.000000  ...               0.100000   \n",
       "max        116.000000    128.000000     91.000000  ...               1.000000   \n",
       "\n",
       "       max_positive_polarity  avg_negative_polarity  min_negative_polarity  \\\n",
       "count           39644.000000           39644.000000           39644.000000   \n",
       "mean                0.756728              -0.259524              -0.521944   \n",
       "std                 0.247786               0.127726               0.290290   \n",
       "min                 0.000000              -1.000000              -1.000000   \n",
       "25%                 0.600000              -0.328383              -0.700000   \n",
       "50%                 0.800000              -0.253333              -0.500000   \n",
       "75%                 1.000000              -0.186905              -0.300000   \n",
       "max                 1.000000               0.000000               0.000000   \n",
       "\n",
       "       max_negative_polarity  title_subjectivity  title_sentiment_polarity  \\\n",
       "count           39644.000000        39644.000000              39644.000000   \n",
       "mean               -0.107500            0.282353                  0.071425   \n",
       "std                 0.095373            0.324247                  0.265450   \n",
       "min                -1.000000            0.000000                 -1.000000   \n",
       "25%                -0.125000            0.000000                  0.000000   \n",
       "50%                -0.100000            0.150000                  0.000000   \n",
       "75%                -0.050000            0.500000                  0.150000   \n",
       "max                 0.000000            1.000000                  1.000000   \n",
       "\n",
       "       abs_title_subjectivity  abs_title_sentiment_polarity         shares  \n",
       "count            39644.000000                  39644.000000   39644.000000  \n",
       "mean                 0.341843                      0.156064    3395.380184  \n",
       "std                  0.188791                      0.226294   11626.950749  \n",
       "min                  0.000000                      0.000000       1.000000  \n",
       "25%                  0.166667                      0.000000     946.000000  \n",
       "50%                  0.500000                      0.000000    1400.000000  \n",
       "75%                  0.500000                      0.250000    2800.000000  \n",
       "max                  0.500000                      1.000000  843300.000000  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.columns = [x.strip() for x in news.columns]\n",
    "news.columns\n",
    "news.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faee7718",
   "metadata": {},
   "source": [
    "Are the range of the values in each column very different?  \n",
    "The columns have maximum values in the hundreds, thousands, cero and one.  \n",
    "And even the value we are trying to predict, **shares**, has a very wide distribution. Let's see.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7d60a944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "news['shares'].plot(kind='hist',bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54d52df",
   "metadata": {},
   "source": [
    "Why is this a problem?  \n",
    "Recall: when we fit a line through a dataset, we are finding the solution to:  \n",
    "$y=X\\beta$  \n",
    "> - $y$ is a repsonse variable, in this case \"shares\".  \n",
    "> - $\\beta$ is the vector slopes by which we increase/decrease the value of the response for 1 unit change a column of $X$.\n",
    "> - If the response is logarithmically distributed, then the coefficients will be biased to accomodate extremely large points in order to minimize the total error of the fit given by:\n",
    "\n",
    "$\\sum_{i=1}^n (y-X\\beta)^2 $\n",
    "\n",
    "**Solution**\n",
    "> To reduce the effect, we can logarithmically transform the response variable, it makes a distribution that looks more like a normal curve:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "72b9f5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#######previous code\n",
    "#news['shares'].plot(kind='hist',bins=100)\n",
    "#######now changing with log to accommodate so that with have a more a normal distribution\n",
    "news['shares'].map(lambda x: np.log10(x)).plot(kind='hist',bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42da8103",
   "metadata": {},
   "source": [
    "The rule of thumb holds true for the predictor variables, $X$.  \n",
    "- If some predictors are larger than other, the solution will mainly emphasize those with the largest range.  \n",
    "- They will contribute most to the overall error.  \n",
    "- We can systemically scale all of our variables with the logarithmic transformation.\n",
    "- To do this we need to remove all the variable that are not useful, like \"URL\" is a textual data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950d6a09",
   "metadata": {},
   "source": [
    "**SETEP 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d17b6f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the undefined before the first : means we are leaving out the first column, \n",
    "#only taken from timedelta until shares.\n",
    "news.head()\n",
    "news_trimmed_features = news.drop(['url'],axis=1) #axis1 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "083f06aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>731.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "0      731.0            12.0             219.0         0.663594   \n",
       "1      731.0             9.0             255.0         0.604743   \n",
       "2      731.0             9.0             211.0         0.575130   \n",
       "3      731.0             9.0             531.0         0.503788   \n",
       "4      731.0            13.0            1072.0         0.415646   \n",
       "\n",
       "   n_non_stop_words  n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  \\\n",
       "0               1.0                  0.815385        4.0             2.0   \n",
       "1               1.0                  0.791946        3.0             1.0   \n",
       "2               1.0                  0.663866        3.0             1.0   \n",
       "3               1.0                  0.665635        9.0             0.0   \n",
       "4               1.0                  0.540890       19.0            19.0   \n",
       "\n",
       "   num_imgs  num_videos  ...  min_positive_polarity  max_positive_polarity  \\\n",
       "0       1.0         0.0  ...               0.100000                    0.7   \n",
       "1       1.0         0.0  ...               0.033333                    0.7   \n",
       "2       1.0         0.0  ...               0.100000                    1.0   \n",
       "3       1.0         0.0  ...               0.136364                    0.8   \n",
       "4      20.0         0.0  ...               0.033333                    1.0   \n",
       "\n",
       "   avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
       "0              -0.350000                 -0.600              -0.200000   \n",
       "1              -0.118750                 -0.125              -0.100000   \n",
       "2              -0.466667                 -0.800              -0.133333   \n",
       "3              -0.369697                 -0.600              -0.166667   \n",
       "4              -0.220192                 -0.500              -0.050000   \n",
       "\n",
       "   title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0            0.500000                 -0.187500                0.000000   \n",
       "1            0.000000                  0.000000                0.500000   \n",
       "2            0.000000                  0.000000                0.500000   \n",
       "3            0.000000                  0.000000                0.500000   \n",
       "4            0.454545                  0.136364                0.045455   \n",
       "\n",
       "   abs_title_sentiment_polarity  shares  \n",
       "0                      0.187500     593  \n",
       "1                      0.000000     711  \n",
       "2                      0.000000    1500  \n",
       "3                      0.000000    1200  \n",
       "4                      0.136364     505  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_trimmed_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61c5c03",
   "metadata": {},
   "source": [
    "**STEP 2**\n",
    "- Identify the variable we want to transform, with the rule of Thumb (their max, given by the 8th row(index 7) of the describe() method is >1, indicating that they are not in the range 0 to 1).\n",
    "- Apply the log method to transform.\n",
    "- Keep in mind that is necessary to add the number 1 to each logarithmically transformed variable so that we avoid errors for taking the algorithm of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5fa04613",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>354.530471</td>\n",
       "      <td>10.398749</td>\n",
       "      <td>546.514731</td>\n",
       "      <td>0.548216</td>\n",
       "      <td>0.996469</td>\n",
       "      <td>0.689175</td>\n",
       "      <td>10.883690</td>\n",
       "      <td>3.293638</td>\n",
       "      <td>4.544143</td>\n",
       "      <td>1.249874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095446</td>\n",
       "      <td>0.756728</td>\n",
       "      <td>-0.259524</td>\n",
       "      <td>-0.521944</td>\n",
       "      <td>-0.107500</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.071425</td>\n",
       "      <td>0.341843</td>\n",
       "      <td>0.156064</td>\n",
       "      <td>3395.380184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>214.163767</td>\n",
       "      <td>2.114037</td>\n",
       "      <td>471.107508</td>\n",
       "      <td>3.520708</td>\n",
       "      <td>5.231231</td>\n",
       "      <td>3.264816</td>\n",
       "      <td>11.332017</td>\n",
       "      <td>3.855141</td>\n",
       "      <td>8.309434</td>\n",
       "      <td>4.107855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071315</td>\n",
       "      <td>0.247786</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>0.290290</td>\n",
       "      <td>0.095373</td>\n",
       "      <td>0.324247</td>\n",
       "      <td>0.265450</td>\n",
       "      <td>0.188791</td>\n",
       "      <td>0.226294</td>\n",
       "      <td>11626.950749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>164.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>0.470870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625739</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.328383</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>946.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>339.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>0.539226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.253333</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>542.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>716.000000</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.754630</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.186905</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>731.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>8474.000000</td>\n",
       "      <td>701.000000</td>\n",
       "      <td>1042.000000</td>\n",
       "      <td>650.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "count  39644.000000    39644.000000      39644.000000     39644.000000   \n",
       "mean     354.530471       10.398749        546.514731         0.548216   \n",
       "std      214.163767        2.114037        471.107508         3.520708   \n",
       "min        8.000000        2.000000          0.000000         0.000000   \n",
       "25%      164.000000        9.000000        246.000000         0.470870   \n",
       "50%      339.000000       10.000000        409.000000         0.539226   \n",
       "75%      542.000000       12.000000        716.000000         0.608696   \n",
       "max      731.000000       23.000000       8474.000000       701.000000   \n",
       "\n",
       "       n_non_stop_words  n_non_stop_unique_tokens     num_hrefs  \\\n",
       "count      39644.000000              39644.000000  39644.000000   \n",
       "mean           0.996469                  0.689175     10.883690   \n",
       "std            5.231231                  3.264816     11.332017   \n",
       "min            0.000000                  0.000000      0.000000   \n",
       "25%            1.000000                  0.625739      4.000000   \n",
       "50%            1.000000                  0.690476      8.000000   \n",
       "75%            1.000000                  0.754630     14.000000   \n",
       "max         1042.000000                650.000000    304.000000   \n",
       "\n",
       "       num_self_hrefs      num_imgs    num_videos  ...  min_positive_polarity  \\\n",
       "count    39644.000000  39644.000000  39644.000000  ...           39644.000000   \n",
       "mean         3.293638      4.544143      1.249874  ...               0.095446   \n",
       "std          3.855141      8.309434      4.107855  ...               0.071315   \n",
       "min          0.000000      0.000000      0.000000  ...               0.000000   \n",
       "25%          1.000000      1.000000      0.000000  ...               0.050000   \n",
       "50%          3.000000      1.000000      0.000000  ...               0.100000   \n",
       "75%          4.000000      4.000000      1.000000  ...               0.100000   \n",
       "max        116.000000    128.000000     91.000000  ...               1.000000   \n",
       "\n",
       "       max_positive_polarity  avg_negative_polarity  min_negative_polarity  \\\n",
       "count           39644.000000           39644.000000           39644.000000   \n",
       "mean                0.756728              -0.259524              -0.521944   \n",
       "std                 0.247786               0.127726               0.290290   \n",
       "min                 0.000000              -1.000000              -1.000000   \n",
       "25%                 0.600000              -0.328383              -0.700000   \n",
       "50%                 0.800000              -0.253333              -0.500000   \n",
       "75%                 1.000000              -0.186905              -0.300000   \n",
       "max                 1.000000               0.000000               0.000000   \n",
       "\n",
       "       max_negative_polarity  title_subjectivity  title_sentiment_polarity  \\\n",
       "count           39644.000000        39644.000000              39644.000000   \n",
       "mean               -0.107500            0.282353                  0.071425   \n",
       "std                 0.095373            0.324247                  0.265450   \n",
       "min                -1.000000            0.000000                 -1.000000   \n",
       "25%                -0.125000            0.000000                  0.000000   \n",
       "50%                -0.100000            0.150000                  0.000000   \n",
       "75%                -0.050000            0.500000                  0.150000   \n",
       "max                 0.000000            1.000000                  1.000000   \n",
       "\n",
       "       abs_title_subjectivity  abs_title_sentiment_polarity         shares  \n",
       "count            39644.000000                  39644.000000   39644.000000  \n",
       "mean                 0.341843                      0.156064    3395.380184  \n",
       "std                  0.188791                      0.226294   11626.950749  \n",
       "min                  0.000000                      0.000000       1.000000  \n",
       "25%                  0.166667                      0.000000     946.000000  \n",
       "50%                  0.500000                      0.000000    1400.000000  \n",
       "75%                  0.500000                      0.250000    2800.000000  \n",
       "max                  0.500000                      1.000000  843300.000000  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_trimmed_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "98d00884",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what it makes is to convert all the values in the *max* row greater than 1 with log method in a fit value.\n",
    "log_values = list(news_trimmed_features.columns[news_trimmed_features.describe().reset_index().loc[7][1:]>1])\n",
    "for n in log_values:\n",
    "    news_trimmed_features[n] = np.log10(news_trimmed_features[n]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6c714df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.531735</td>\n",
       "      <td>0.311212</td>\n",
       "      <td>0.542389</td>\n",
       "      <td>0.072653</td>\n",
       "      <td>0.110895</td>\n",
       "      <td>0.086453</td>\n",
       "      <td>0.279180</td>\n",
       "      <td>0.174377</td>\n",
       "      <td>0.155810</td>\n",
       "      <td>0.058978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095446</td>\n",
       "      <td>0.756728</td>\n",
       "      <td>-0.259524</td>\n",
       "      <td>-0.521944</td>\n",
       "      <td>-0.107500</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.071425</td>\n",
       "      <td>0.341843</td>\n",
       "      <td>0.156064</td>\n",
       "      <td>0.626168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.053246</td>\n",
       "      <td>0.017761</td>\n",
       "      <td>0.102107</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>0.019587</td>\n",
       "      <td>0.017908</td>\n",
       "      <td>0.085195</td>\n",
       "      <td>0.089444</td>\n",
       "      <td>0.114781</td>\n",
       "      <td>0.090675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071315</td>\n",
       "      <td>0.247786</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>0.290290</td>\n",
       "      <td>0.095373</td>\n",
       "      <td>0.324247</td>\n",
       "      <td>0.265450</td>\n",
       "      <td>0.188791</td>\n",
       "      <td>0.226294</td>\n",
       "      <td>0.040056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.290978</td>\n",
       "      <td>0.169416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.507516</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.530545</td>\n",
       "      <td>0.067285</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.083162</td>\n",
       "      <td>0.230186</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.328383</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.599485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.547957</td>\n",
       "      <td>0.309927</td>\n",
       "      <td>0.557842</td>\n",
       "      <td>0.074561</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.089202</td>\n",
       "      <td>0.290978</td>\n",
       "      <td>0.204679</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.253333</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.617675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.572267</td>\n",
       "      <td>0.325093</td>\n",
       "      <td>0.586083</td>\n",
       "      <td>0.081518</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.094885</td>\n",
       "      <td>0.337677</td>\n",
       "      <td>0.230186</td>\n",
       "      <td>0.230186</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.186905</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.648098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.587095</td>\n",
       "      <td>0.376616</td>\n",
       "      <td>0.692683</td>\n",
       "      <td>0.585047</td>\n",
       "      <td>0.604041</td>\n",
       "      <td>0.581333</td>\n",
       "      <td>0.542116</td>\n",
       "      <td>0.486882</td>\n",
       "      <td>0.492843</td>\n",
       "      <td>0.471847</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.840481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "count  39644.000000    39644.000000      39644.000000     39644.000000   \n",
       "mean       0.531735        0.311212          0.542389         0.072653   \n",
       "std        0.053246        0.017761          0.102107         0.016611   \n",
       "min        0.290978        0.169416          0.000000         0.000000   \n",
       "25%        0.507516        0.301030          0.530545         0.067285   \n",
       "50%        0.547957        0.309927          0.557842         0.074561   \n",
       "75%        0.572267        0.325093          0.586083         0.081518   \n",
       "max        0.587095        0.376616          0.692683         0.585047   \n",
       "\n",
       "       n_non_stop_words  n_non_stop_unique_tokens     num_hrefs  \\\n",
       "count      39644.000000              39644.000000  39644.000000   \n",
       "mean           0.110895                  0.086453      0.279180   \n",
       "std            0.019587                  0.017908      0.085195   \n",
       "min            0.000000                  0.000000      0.000000   \n",
       "25%            0.114287                  0.083162      0.230186   \n",
       "50%            0.114287                  0.089202      0.290978   \n",
       "75%            0.114287                  0.094885      0.337677   \n",
       "max            0.604041                  0.581333      0.542116   \n",
       "\n",
       "       num_self_hrefs      num_imgs    num_videos  ...  min_positive_polarity  \\\n",
       "count    39644.000000  39644.000000  39644.000000  ...           39644.000000   \n",
       "mean         0.174377      0.155810      0.058978  ...               0.095446   \n",
       "std          0.089444      0.114781      0.090675  ...               0.071315   \n",
       "min          0.000000      0.000000      0.000000  ...               0.000000   \n",
       "25%          0.114287      0.114287      0.000000  ...               0.050000   \n",
       "50%          0.204679      0.114287      0.000000  ...               0.100000   \n",
       "75%          0.230186      0.230186      0.114287  ...               0.100000   \n",
       "max          0.486882      0.492843      0.471847  ...               1.000000   \n",
       "\n",
       "       max_positive_polarity  avg_negative_polarity  min_negative_polarity  \\\n",
       "count           39644.000000           39644.000000           39644.000000   \n",
       "mean                0.756728              -0.259524              -0.521944   \n",
       "std                 0.247786               0.127726               0.290290   \n",
       "min                 0.000000              -1.000000              -1.000000   \n",
       "25%                 0.600000              -0.328383              -0.700000   \n",
       "50%                 0.800000              -0.253333              -0.500000   \n",
       "75%                 1.000000              -0.186905              -0.300000   \n",
       "max                 1.000000               0.000000               0.000000   \n",
       "\n",
       "       max_negative_polarity  title_subjectivity  title_sentiment_polarity  \\\n",
       "count           39644.000000        39644.000000              39644.000000   \n",
       "mean               -0.107500            0.282353                  0.071425   \n",
       "std                 0.095373            0.324247                  0.265450   \n",
       "min                -1.000000            0.000000                 -1.000000   \n",
       "25%                -0.125000            0.000000                  0.000000   \n",
       "50%                -0.100000            0.150000                  0.000000   \n",
       "75%                -0.050000            0.500000                  0.150000   \n",
       "max                 0.000000            1.000000                  1.000000   \n",
       "\n",
       "       abs_title_subjectivity  abs_title_sentiment_polarity        shares  \n",
       "count            39644.000000                  39644.000000  39644.000000  \n",
       "mean                 0.341843                      0.156064      0.626168  \n",
       "std                  0.188791                      0.226294      0.040056  \n",
       "min                  0.000000                      0.000000      0.114287  \n",
       "25%                  0.166667                      0.000000      0.599485  \n",
       "50%                  0.500000                      0.000000      0.617675  \n",
       "75%                  0.500000                      0.250000      0.648098  \n",
       "max                  0.500000                      1.000000      0.840481  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_trimmed_features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346c6ada",
   "metadata": {},
   "source": [
    "**STEP 3**  \n",
    "- To analyse to see if there are infinite or nonexistent values.\n",
    "- Remove them.\n",
    "- To do that we are going to convert infinite values to the placeholder 'not a number' or NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d82d8c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timedelta                            0\n",
       "n_tokens_title                       0\n",
       "n_tokens_content                     0\n",
       "n_unique_tokens                      0\n",
       "n_non_stop_words                     0\n",
       "n_non_stop_unique_tokens             0\n",
       "num_hrefs                            0\n",
       "num_self_hrefs                       0\n",
       "num_imgs                             0\n",
       "num_videos                           0\n",
       "average_token_length                 0\n",
       "num_keywords                         0\n",
       "data_channel_is_lifestyle            0\n",
       "data_channel_is_entertainment        0\n",
       "data_channel_is_bus                  0\n",
       "data_channel_is_socmed               0\n",
       "data_channel_is_tech                 0\n",
       "data_channel_is_world                0\n",
       "kw_min_min                       22980\n",
       "kw_max_min                           0\n",
       "kw_avg_min                         694\n",
       "kw_min_max                           0\n",
       "kw_max_max                           0\n",
       "kw_avg_max                           0\n",
       "kw_min_avg                           6\n",
       "kw_max_avg                           0\n",
       "kw_avg_avg                           0\n",
       "self_reference_min_shares            0\n",
       "self_reference_max_shares            0\n",
       "self_reference_avg_sharess           0\n",
       "weekday_is_monday                    0\n",
       "weekday_is_tuesday                   0\n",
       "weekday_is_wednesday                 0\n",
       "weekday_is_thursday                  0\n",
       "weekday_is_friday                    0\n",
       "weekday_is_saturday                  0\n",
       "weekday_is_sunday                    0\n",
       "is_weekend                           0\n",
       "LDA_00                               0\n",
       "LDA_01                               0\n",
       "LDA_02                               0\n",
       "LDA_03                               0\n",
       "LDA_04                               0\n",
       "global_subjectivity                  0\n",
       "global_sentiment_polarity            0\n",
       "global_rate_positive_words           0\n",
       "global_rate_negative_words           0\n",
       "rate_positive_words                  0\n",
       "rate_negative_words                  0\n",
       "avg_positive_polarity                0\n",
       "min_positive_polarity                0\n",
       "max_positive_polarity                0\n",
       "avg_negative_polarity                0\n",
       "min_negative_polarity                0\n",
       "max_negative_polarity                0\n",
       "title_subjectivity                   0\n",
       "title_sentiment_polarity             0\n",
       "abs_title_subjectivity               0\n",
       "abs_title_sentiment_polarity         0\n",
       "shares                               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_trimmed_features.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9e587dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23680"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to see in total how many null values there are.\n",
    "news_trimmed_features.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4cc39fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timedelta                        39644\n",
       "n_tokens_title                   39644\n",
       "n_tokens_content                 39644\n",
       "n_unique_tokens                  39644\n",
       "n_non_stop_words                 39644\n",
       "n_non_stop_unique_tokens         39644\n",
       "num_hrefs                        39644\n",
       "num_self_hrefs                   39644\n",
       "num_imgs                         39644\n",
       "num_videos                       39644\n",
       "average_token_length             39644\n",
       "num_keywords                     39644\n",
       "data_channel_is_lifestyle        39644\n",
       "data_channel_is_entertainment    39644\n",
       "data_channel_is_bus              39644\n",
       "data_channel_is_socmed           39644\n",
       "data_channel_is_tech             39644\n",
       "data_channel_is_world            39644\n",
       "kw_min_min                       16664\n",
       "kw_max_min                       39644\n",
       "kw_avg_min                       38950\n",
       "kw_min_max                       39644\n",
       "kw_max_max                       39644\n",
       "kw_avg_max                       39644\n",
       "kw_min_avg                       39638\n",
       "kw_max_avg                       39644\n",
       "kw_avg_avg                       39644\n",
       "self_reference_min_shares        39644\n",
       "self_reference_max_shares        39644\n",
       "self_reference_avg_sharess       39644\n",
       "weekday_is_monday                39644\n",
       "weekday_is_tuesday               39644\n",
       "weekday_is_wednesday             39644\n",
       "weekday_is_thursday              39644\n",
       "weekday_is_friday                39644\n",
       "weekday_is_saturday              39644\n",
       "weekday_is_sunday                39644\n",
       "is_weekend                       39644\n",
       "LDA_00                           39644\n",
       "LDA_01                           39644\n",
       "LDA_02                           39644\n",
       "LDA_03                           39644\n",
       "LDA_04                           39644\n",
       "global_subjectivity              39644\n",
       "global_sentiment_polarity        39644\n",
       "global_rate_positive_words       39644\n",
       "global_rate_negative_words       39644\n",
       "rate_positive_words              39644\n",
       "rate_negative_words              39644\n",
       "avg_positive_polarity            39644\n",
       "min_positive_polarity            39644\n",
       "max_positive_polarity            39644\n",
       "avg_negative_polarity            39644\n",
       "min_negative_polarity            39644\n",
       "max_negative_polarity            39644\n",
       "title_subjectivity               39644\n",
       "title_sentiment_polarity         39644\n",
       "abs_title_subjectivity           39644\n",
       "abs_title_sentiment_polarity     39644\n",
       "shares                           39644\n",
       "dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_trimmed_features.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "97f4b80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_trimmed_features = news_trimmed_features.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5548fd1a",
   "metadata": {},
   "source": [
    "**STEP 4**  \n",
    "With the *fill* function to substitute the NaN placeholder with the proceeding value in the column or is possible to use a fixed value, but in this case with the preceedinf value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "95b36f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_trimmed_features = news_trimmed_features.fillna(method='pad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a92db466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_trimmed_features.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb981ed4",
   "metadata": {},
   "source": [
    "**STEP 5**  \n",
    "Now split the data into a response variable ('shares') and the features (all the rest os the columns). These are the inputs in the **regression models** described later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "640a8500",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_response = news_trimmed_features['shares']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4a177fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.576777\n",
       "1    0.585740\n",
       "2    0.620800\n",
       "3    0.610612\n",
       "4    0.568689\n",
       "Name: shares, dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_response.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8a41ab9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.587095</td>\n",
       "      <td>0.325093</td>\n",
       "      <td>0.524061</td>\n",
       "      <td>0.086733</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.100015</td>\n",
       "      <td>0.230186</td>\n",
       "      <td>0.169416</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378636</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.587095</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.532530</td>\n",
       "      <td>0.081133</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.098064</td>\n",
       "      <td>0.204679</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286915</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.587095</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.521966</td>\n",
       "      <td>0.078209</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.086758</td>\n",
       "      <td>0.204679</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495833</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.587095</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.571233</td>\n",
       "      <td>0.070845</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.086922</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.587095</td>\n",
       "      <td>0.331656</td>\n",
       "      <td>0.605370</td>\n",
       "      <td>0.061058</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.074733</td>\n",
       "      <td>0.361922</td>\n",
       "      <td>0.361922</td>\n",
       "      <td>0.365903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411127</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "0   0.587095        0.325093          0.524061         0.086733   \n",
       "1   0.587095        0.301030          0.532530         0.081133   \n",
       "2   0.587095        0.301030          0.521966         0.078209   \n",
       "3   0.587095        0.301030          0.571233         0.070845   \n",
       "4   0.587095        0.331656          0.605370         0.061058   \n",
       "\n",
       "   n_non_stop_words  n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  \\\n",
       "0          0.114287                  0.100015   0.230186        0.169416   \n",
       "1          0.114287                  0.098064   0.204679        0.114287   \n",
       "2          0.114287                  0.086758   0.204679        0.114287   \n",
       "3          0.114287                  0.086922   0.301030        0.000000   \n",
       "4          0.114287                  0.074733   0.361922        0.361922   \n",
       "\n",
       "   num_imgs  num_videos  ...  avg_positive_polarity  min_positive_polarity  \\\n",
       "0  0.114287         0.0  ...               0.378636               0.100000   \n",
       "1  0.114287         0.0  ...               0.286915               0.033333   \n",
       "2  0.114287         0.0  ...               0.495833               0.100000   \n",
       "3  0.114287         0.0  ...               0.385965               0.136364   \n",
       "4  0.365903         0.0  ...               0.411127               0.033333   \n",
       "\n",
       "   max_positive_polarity  avg_negative_polarity  min_negative_polarity  \\\n",
       "0                    0.7              -0.350000                 -0.600   \n",
       "1                    0.7              -0.118750                 -0.125   \n",
       "2                    1.0              -0.466667                 -0.800   \n",
       "3                    0.8              -0.369697                 -0.600   \n",
       "4                    1.0              -0.220192                 -0.500   \n",
       "\n",
       "   max_negative_polarity  title_subjectivity  title_sentiment_polarity  \\\n",
       "0              -0.200000            0.500000                 -0.187500   \n",
       "1              -0.100000            0.000000                  0.000000   \n",
       "2              -0.133333            0.000000                  0.000000   \n",
       "3              -0.166667            0.000000                  0.000000   \n",
       "4              -0.050000            0.454545                  0.136364   \n",
       "\n",
       "   abs_title_subjectivity  abs_title_sentiment_polarity  \n",
       "0                0.000000                      0.187500  \n",
       "1                0.500000                      0.000000  \n",
       "2                0.500000                      0.000000  \n",
       "3                0.500000                      0.000000  \n",
       "4                0.045455                      0.136364  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_trimmed_features = news_trimmed_features.loc[:,'timedelta':'abs_title_sentiment_polarity']\n",
    "news_trimmed_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e992ca73",
   "metadata": {},
   "source": [
    "**STEP 5:**\n",
    "- Let's take a look at variables that we did not transform logarithmically. \n",
    "- At this point is possible to find the linear model, but, the slopes for many of these will be extremely large or small. \n",
    "- That happens because, i.e one set of columns which we did not logarithmically transform encodes a $0/1$ value for whether a news article was published on a given day of the week.\n",
    "- Another (Latent Dirichlet Allocation) gives a $0/1$ indicator for whether an article was tagged with a particular algorithmically defined topic.  \n",
    "- In both cases, any row in the dataset must have the value 1 in one of the columns of these features, i.e the day of week has to take one of the seven potential values, why is this a problem?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a58a0ca",
   "metadata": {},
   "source": [
    "- Recall that in most linear fits, we have both, a slope and an intercept, which is the offset of the line vertically from the origin (0,0) of the x-y plane.\n",
    "- In a linear model we represent the multi-dimensional intercept by a column af all 1 in the feature matrix X, which will be added by defautl in many model-fitting libraries. \n",
    "- That means that a set of values, i.e the days of the week, since they are independent, **could form a linear combinations that exactly equeals the intercept column**, making it impossible to find a unique solution for the $\\beta$ slopes.\n",
    "- **This is the same issue as the last assumptionof LR, in which the matrix (XTX) is not invertible**, so, we cannot be obtaining a numerically stable solution for the coefficients. \n",
    "- The instability results in the unreasonably large coefficient values you will observe if you were to fit a regression model on this dataset.\n",
    "\n",
    "\n",
    "SOLUTION: \n",
    "> We either need to leave out the intercept column(specifying accordingly the library), **or leave out one of the columns for these binary variables**. In this case fits better the second option, to drop one columns from each set of binary features.\n",
    "\n",
    "**So the 5 point is to drop one columns from each set of binary features**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "66a3ad0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.531735</td>\n",
       "      <td>0.311212</td>\n",
       "      <td>0.542389</td>\n",
       "      <td>0.072653</td>\n",
       "      <td>0.110895</td>\n",
       "      <td>0.086453</td>\n",
       "      <td>0.279180</td>\n",
       "      <td>0.174377</td>\n",
       "      <td>0.155810</td>\n",
       "      <td>0.058978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.095446</td>\n",
       "      <td>0.756728</td>\n",
       "      <td>-0.259524</td>\n",
       "      <td>-0.521944</td>\n",
       "      <td>-0.107500</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.071425</td>\n",
       "      <td>0.341843</td>\n",
       "      <td>0.156064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.053246</td>\n",
       "      <td>0.017761</td>\n",
       "      <td>0.102107</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>0.019587</td>\n",
       "      <td>0.017908</td>\n",
       "      <td>0.085195</td>\n",
       "      <td>0.089444</td>\n",
       "      <td>0.114781</td>\n",
       "      <td>0.090675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104542</td>\n",
       "      <td>0.071315</td>\n",
       "      <td>0.247786</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>0.290290</td>\n",
       "      <td>0.095373</td>\n",
       "      <td>0.324247</td>\n",
       "      <td>0.265450</td>\n",
       "      <td>0.188791</td>\n",
       "      <td>0.226294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.290978</td>\n",
       "      <td>0.169416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.507516</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.530545</td>\n",
       "      <td>0.067285</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.083162</td>\n",
       "      <td>0.230186</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306244</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.328383</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.547957</td>\n",
       "      <td>0.309927</td>\n",
       "      <td>0.557842</td>\n",
       "      <td>0.074561</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.089202</td>\n",
       "      <td>0.290978</td>\n",
       "      <td>0.204679</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358755</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.253333</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.572267</td>\n",
       "      <td>0.325093</td>\n",
       "      <td>0.586083</td>\n",
       "      <td>0.081518</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.094885</td>\n",
       "      <td>0.337677</td>\n",
       "      <td>0.230186</td>\n",
       "      <td>0.230186</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411428</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.186905</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.587095</td>\n",
       "      <td>0.376616</td>\n",
       "      <td>0.692683</td>\n",
       "      <td>0.585047</td>\n",
       "      <td>0.604041</td>\n",
       "      <td>0.581333</td>\n",
       "      <td>0.542116</td>\n",
       "      <td>0.486882</td>\n",
       "      <td>0.492843</td>\n",
       "      <td>0.471847</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "count  39644.000000    39644.000000      39644.000000     39644.000000   \n",
       "mean       0.531735        0.311212          0.542389         0.072653   \n",
       "std        0.053246        0.017761          0.102107         0.016611   \n",
       "min        0.290978        0.169416          0.000000         0.000000   \n",
       "25%        0.507516        0.301030          0.530545         0.067285   \n",
       "50%        0.547957        0.309927          0.557842         0.074561   \n",
       "75%        0.572267        0.325093          0.586083         0.081518   \n",
       "max        0.587095        0.376616          0.692683         0.585047   \n",
       "\n",
       "       n_non_stop_words  n_non_stop_unique_tokens     num_hrefs  \\\n",
       "count      39644.000000              39644.000000  39644.000000   \n",
       "mean           0.110895                  0.086453      0.279180   \n",
       "std            0.019587                  0.017908      0.085195   \n",
       "min            0.000000                  0.000000      0.000000   \n",
       "25%            0.114287                  0.083162      0.230186   \n",
       "50%            0.114287                  0.089202      0.290978   \n",
       "75%            0.114287                  0.094885      0.337677   \n",
       "max            0.604041                  0.581333      0.542116   \n",
       "\n",
       "       num_self_hrefs      num_imgs    num_videos  ...  avg_positive_polarity  \\\n",
       "count    39644.000000  39644.000000  39644.000000  ...           39644.000000   \n",
       "mean         0.174377      0.155810      0.058978  ...               0.353825   \n",
       "std          0.089444      0.114781      0.090675  ...               0.104542   \n",
       "min          0.000000      0.000000      0.000000  ...               0.000000   \n",
       "25%          0.114287      0.114287      0.000000  ...               0.306244   \n",
       "50%          0.204679      0.114287      0.000000  ...               0.358755   \n",
       "75%          0.230186      0.230186      0.114287  ...               0.411428   \n",
       "max          0.486882      0.492843      0.471847  ...               1.000000   \n",
       "\n",
       "       min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "count           39644.000000           39644.000000           39644.000000   \n",
       "mean                0.095446               0.756728              -0.259524   \n",
       "std                 0.071315               0.247786               0.127726   \n",
       "min                 0.000000               0.000000              -1.000000   \n",
       "25%                 0.050000               0.600000              -0.328383   \n",
       "50%                 0.100000               0.800000              -0.253333   \n",
       "75%                 0.100000               1.000000              -0.186905   \n",
       "max                 1.000000               1.000000               0.000000   \n",
       "\n",
       "       min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "count           39644.000000           39644.000000        39644.000000   \n",
       "mean               -0.521944              -0.107500            0.282353   \n",
       "std                 0.290290               0.095373            0.324247   \n",
       "min                -1.000000              -1.000000            0.000000   \n",
       "25%                -0.700000              -0.125000            0.000000   \n",
       "50%                -0.500000              -0.100000            0.150000   \n",
       "75%                -0.300000              -0.050000            0.500000   \n",
       "max                 0.000000               0.000000            1.000000   \n",
       "\n",
       "       title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "count              39644.000000            39644.000000   \n",
       "mean                   0.071425                0.341843   \n",
       "std                    0.265450                0.188791   \n",
       "min                   -1.000000                0.000000   \n",
       "25%                    0.000000                0.166667   \n",
       "50%                    0.000000                0.500000   \n",
       "75%                    0.150000                0.500000   \n",
       "max                    1.000000                0.500000   \n",
       "\n",
       "       abs_title_sentiment_polarity  \n",
       "count                  39644.000000  \n",
       "mean                       0.156064  \n",
       "std                        0.226294  \n",
       "min                        0.000000  \n",
       "25%                        0.000000  \n",
       "50%                        0.000000  \n",
       "75%                        0.250000  \n",
       "max                        1.000000  \n",
       "\n",
       "[8 rows x 59 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_trimmed_features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1046cef5",
   "metadata": {},
   "source": [
    "Looking for the binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0aaef063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gives the columns and  with binary \n",
    "#x = news_trimmed_features.loc[:, news_trimmed_features.isin([0,1]).all()]\n",
    "#x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3701a208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "52db012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to filter the column names with binary features\n",
    "#c = news_trimmed_features.columns[news_trimmed_features.isin([0,1]).all()]\n",
    "#c = news_trimmed_features.isin([0,1]).all()\n",
    "#c\n",
    "#m = c.sum()\n",
    "#print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2566d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#news_trimmed_features['LDA_00'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "902dbb59",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ros22\\AppData\\Local\\Temp\\ipykernel_26680\\1056272052.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  news_trimmed_features = news_trimmed_features.drop('weekday_is_sunday',1)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['weekday_is_sunday'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[120], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m news_trimmed_features \u001b[38;5;241m=\u001b[39m \u001b[43mnews_trimmed_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweekday_is_sunday\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\pandas\\core\\frame.py:5399\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5251\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   5252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   5253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5260\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5261\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5262\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5263\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5264\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5397\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5398\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5401\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5405\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5406\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5407\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\pandas\\core\\generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4503\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4505\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\pandas\\core\\generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4544\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4546\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4547\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4549\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6934\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6934\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6935\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6936\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['weekday_is_sunday'] not found in axis\""
     ]
    }
   ],
   "source": [
    "news_trimmed_features = news_trimmed_features.drop('weekday_is_sunday',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "573d84b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ros22\\AppData\\Local\\Temp\\ipykernel_26680\\1272921246.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  news_trimmed_features = news_trimmed_features.drop('LDA_00',1)\n"
     ]
    }
   ],
   "source": [
    "news_trimmed_features = news_trimmed_features.drop('LDA_00',1) \n",
    "#this error happens because we already delete these columns, so if trying to get these columns after running this code that error happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "93cb6e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timedelta', 'n_tokens_title', 'n_tokens_content', 'n_unique_tokens',\n",
       "       'n_non_stop_words', 'n_non_stop_unique_tokens', 'num_hrefs',\n",
       "       'num_self_hrefs', 'num_imgs', 'num_videos', 'average_token_length',\n",
       "       'num_keywords', 'data_channel_is_lifestyle',\n",
       "       'data_channel_is_entertainment', 'data_channel_is_bus',\n",
       "       'data_channel_is_socmed', 'data_channel_is_tech',\n",
       "       'data_channel_is_world', 'kw_min_min', 'kw_max_min', 'kw_avg_min',\n",
       "       'kw_min_max', 'kw_max_max', 'kw_avg_max', 'kw_min_avg', 'kw_max_avg',\n",
       "       'kw_avg_avg', 'self_reference_min_shares', 'self_reference_max_shares',\n",
       "       'self_reference_avg_sharess', 'weekday_is_monday', 'weekday_is_tuesday',\n",
       "       'weekday_is_wednesday', 'weekday_is_thursday', 'weekday_is_friday',\n",
       "       'weekday_is_saturday', 'is_weekend', 'LDA_01', 'LDA_02', 'LDA_03',\n",
       "       'LDA_04', 'global_subjectivity', 'global_sentiment_polarity',\n",
       "       'global_rate_positive_words', 'global_rate_negative_words',\n",
       "       'rate_positive_words', 'rate_negative_words', 'avg_positive_polarity',\n",
       "       'min_positive_polarity', 'max_positive_polarity',\n",
       "       'avg_negative_polarity', 'min_negative_polarity',\n",
       "       'max_negative_polarity', 'title_subjectivity',\n",
       "       'title_sentiment_polarity', 'abs_title_subjectivity',\n",
       "       'abs_title_sentiment_polarity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_trimmed_features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadb517b",
   "metadata": {},
   "source": [
    "Now we are ready to fit a regression model to our data.  \n",
    "**STEP 6**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44b33a6",
   "metadata": {},
   "source": [
    "**MODEL FITTING AND EVALUATION**  \n",
    "From data to decissions - The goal of modelling can be either:  \n",
    "> a) To predict a future response given historical data.  \n",
    "> b) infer the statistical significance and effect of a given variable on an outcome.  \n",
    "\n",
    "a) The first scenario, we will choose a subset of data to train our model, --- and then evaluate the goodness of fit of the linear model on an independent data set not used to derive the model parameters --- we want to validate that the trends represented by the model generalise beyond a particular set of data points. (queremos validar que las tendencias representadas por el modelo generalizan más allá de un conjunto concreto de puntos de datos) --- While the coefficient output of the linear model are interpretable, we are still more concerned in this scenario about whether we can **accurately** predict future responses rather than the meaning of the coefficients.\n",
    "<br>\n",
    "\n",
    "b) The second scenario, we will use all the dataset to fit a linear model --- so we are more interested in the coefficients of the model and whether they are statistically significant --- also we are interested in comparing models with more or fewer coefficients to determine the most important parameters that predict an outcome.  \n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd2bfbf",
   "metadata": {},
   "source": [
    "Let's continue under the assumption that we are trying to predict future data.  \n",
    "To obtain **test** and **validation data**, we will split the response and predictor data into 60% training and 40% test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f2d32f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_features_train, news_features_test, news_shares_train, news_shares_test = train_test_split(news_trimmed_features, news_response, test_size=0.4, random_state = 0)\n",
    "#the random state argument is because this helps in the randomization to mantain the same random data in every iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44514e5a",
   "metadata": {},
   "source": [
    "With these training and test sets we can then fit the model and compare the predict and observerd values visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cae12220",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmodel = linear_model.LinearRegression().fit(news_features_train, news_shares_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "57c6f6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Prediced')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(news_shares_train, lmodel.predict(news_features_train), color='black')\n",
    "plt.xlabel('Oberved')\n",
    "plt.ylabel('Prediced')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38c8f19",
   "metadata": {},
   "source": [
    "Similarly, let's look at the performance of the model on the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "44c33190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Prediced')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(news_shares_test, lmodel.predict(news_features_test), color='blue')\n",
    "plt.xlabel('Oberved')\n",
    "plt.ylabel('Prediced')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2479729",
   "metadata": {},
   "source": [
    "**COEFFICIENT OF VARIATION R-SAQUARED**  \n",
    "Is a metric often used in regression problems, which defines **how much of the variation in the response is explained by the variation in the predictors** according to the model. The visual similarities are confirmed by looking this metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a0c095",
   "metadata": {},
   "source": [
    "We need the variance and covariance of the two variables, observed response $y$ and the predicted response given by $y\\beta$.  \n",
    "<br>\n",
    "- Perfect score = 1, straight line\n",
    "- no correlation = 0, between a predicted and observed value. i.e. would be an spherical cloud of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "826be1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12697667701816406"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training data\n",
    "lmodel.score(news_features_train, news_shares_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "db635f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10549868903955295"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test data\n",
    "lmodel.score(news_features_test, news_shares_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b96263",
   "metadata": {},
   "source": [
    "There is some relationship between the predicted and observed response captured in the \"news article data\", though we have room for imrpovement (aunque tenemos margen de mejora)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea42dea",
   "metadata": {},
   "source": [
    "Which variables of our imputs are most important in the model?\n",
    "So, we have to sort the coefficients of the model by their absolute magnitude.  \n",
    " - We will obtain the sorted positions of the coefficients.  \n",
    " - Then to re-order the column names using the new index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "97a8a46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['n_unique_tokens', 'n_non_stop_words', 'kw_avg_avg',\n",
       "       'self_reference_avg_sharess', 'n_non_stop_unique_tokens',\n",
       "       'self_reference_max_shares', 'kw_max_max', 'n_tokens_content',\n",
       "       'num_keywords', 'self_reference_min_shares', 'num_hrefs', 'kw_max_avg',\n",
       "       'global_rate_positive_words', 'kw_min_avg', 'num_videos', 'kw_avg_max',\n",
       "       'kw_min_max', 'num_imgs', 'num_self_hrefs', 'global_subjectivity',\n",
       "       'n_tokens_title', 'LDA_02', 'LDA_01', 'LDA_03',\n",
       "       'data_channel_is_entertainment', 'global_rate_negative_words',\n",
       "       'min_positive_polarity', 'global_sentiment_polarity', 'is_weekend',\n",
       "       'LDA_04', 'rate_positive_words', 'data_channel_is_bus', 'kw_max_min',\n",
       "       'data_channel_is_world', 'data_channel_is_lifestyle',\n",
       "       'data_channel_is_socmed', 'abs_title_subjectivity',\n",
       "       'avg_positive_polarity', 'kw_avg_min', 'timedelta',\n",
       "       'title_sentiment_polarity', 'kw_min_min', 'average_token_length',\n",
       "       'max_positive_polarity', 'min_negative_polarity', 'weekday_is_tuesday',\n",
       "       'weekday_is_wednesday', 'rate_negative_words', 'title_subjectivity',\n",
       "       'weekday_is_thursday', 'data_channel_is_tech', 'avg_negative_polarity',\n",
       "       'weekday_is_saturday', 'weekday_is_monday', 'weekday_is_friday',\n",
       "       'max_negative_polarity', 'abs_title_sentiment_polarity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = np.argsort(abs(lmodel.coef_))[::-1]\n",
    "news_trimmed_features.columns[order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13e4e8a",
   "metadata": {},
   "source": [
    "We do not know the confidence interval for a given coefficient value, nor whether it is statistically significant, because there is no information on the variance of the parameter values.  \n",
    "<br>\n",
    "In fact, the **scikit-learn regression method does not calculate statistical significance measurements** and for this reason is better to use a different library **statsmodels**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412bc98d",
   "metadata": {},
   "source": [
    "**STATISTICAL SIGNIFICANCE OF REGRESSION OUTPUTS**  \n",
    "We will use all the data rather than a train/test split.  \n",
    "\n",
    "We have two options to fit the linear model: \"api\" and \"formula.api\".\n",
    "> - Api method: Resembles the scikit-learn function call, except we get a lot more detailed output about the statistical significance of the model.\n",
    "> - Formula.api method: We have to construct a string from the input data representing the formula for the linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dfcb16",
   "metadata": {},
   "source": [
    "**API METHOD:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d87f8f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>shares</td>      <th>  R-squared:         </th>  <td>   0.120</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.119</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   96.55</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 09 Nov 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:43:23</td>     <th>  Log-Likelihood:    </th>  <td>  73840.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 39644</td>      <th>  AIC:               </th> <td>-1.476e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 39587</td>      <th>  BIC:               </th> <td>-1.471e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    56</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                   <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>timedelta</th>                     <td>    0.0038</td> <td>    0.004</td> <td>    0.884</td> <td> 0.377</td> <td>   -0.005</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_tokens_title</th>                <td>    0.0279</td> <td>    0.011</td> <td>    2.474</td> <td> 0.013</td> <td>    0.006</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_tokens_content</th>              <td>   -0.0972</td> <td>    0.017</td> <td>   -5.881</td> <td> 0.000</td> <td>   -0.130</td> <td>   -0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_unique_tokens</th>               <td>   -0.4513</td> <td>    0.087</td> <td>   -5.174</td> <td> 0.000</td> <td>   -0.622</td> <td>   -0.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_non_stop_words</th>              <td>    0.2073</td> <td>    0.089</td> <td>    2.325</td> <td> 0.020</td> <td>    0.033</td> <td>    0.382</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_non_stop_unique_tokens</th>      <td>    0.1834</td> <td>    0.065</td> <td>    2.825</td> <td> 0.005</td> <td>    0.056</td> <td>    0.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_hrefs</th>                     <td>    0.0417</td> <td>    0.004</td> <td>   11.334</td> <td> 0.000</td> <td>    0.035</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_self_hrefs</th>                <td>   -0.0270</td> <td>    0.004</td> <td>   -6.728</td> <td> 0.000</td> <td>   -0.035</td> <td>   -0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_imgs</th>                      <td>    0.0199</td> <td>    0.002</td> <td>    9.051</td> <td> 0.000</td> <td>    0.016</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_videos</th>                    <td>    0.0270</td> <td>    0.002</td> <td>   10.850</td> <td> 0.000</td> <td>    0.022</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>average_token_length</th>          <td>   -0.0135</td> <td>    0.011</td> <td>   -1.279</td> <td> 0.201</td> <td>   -0.034</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_keywords</th>                  <td>    0.0642</td> <td>    0.010</td> <td>    6.457</td> <td> 0.000</td> <td>    0.045</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>data_channel_is_lifestyle</th>     <td>   -0.0057</td> <td>    0.001</td> <td>   -4.380</td> <td> 0.000</td> <td>   -0.008</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>data_channel_is_entertainment</th> <td>   -0.0121</td> <td>    0.001</td> <td>  -14.725</td> <td> 0.000</td> <td>   -0.014</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>data_channel_is_bus</th>           <td>   -0.0106</td> <td>    0.001</td> <td>   -8.494</td> <td> 0.000</td> <td>   -0.013</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>data_channel_is_socmed</th>        <td>    0.0053</td> <td>    0.001</td> <td>    4.356</td> <td> 0.000</td> <td>    0.003</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>data_channel_is_tech</th>          <td>    0.0017</td> <td>    0.001</td> <td>    1.438</td> <td> 0.150</td> <td>   -0.001</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>data_channel_is_world</th>         <td>   -0.0064</td> <td>    0.001</td> <td>   -5.236</td> <td> 0.000</td> <td>   -0.009</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_min_min</th>                    <td>    0.0031</td> <td>    0.002</td> <td>    1.628</td> <td> 0.104</td> <td>   -0.001</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_max_min</th>                    <td>    0.0110</td> <td>    0.003</td> <td>    4.188</td> <td> 0.000</td> <td>    0.006</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_avg_min</th>                    <td>   -0.0061</td> <td>    0.004</td> <td>   -1.676</td> <td> 0.094</td> <td>   -0.013</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_min_max</th>                    <td>    0.0262</td> <td>    0.008</td> <td>    3.473</td> <td> 0.001</td> <td>    0.011</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_max_max</th>                    <td>   -0.1836</td> <td>    0.023</td> <td>   -7.838</td> <td> 0.000</td> <td>   -0.230</td> <td>   -0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_avg_max</th>                    <td>   -0.0023</td> <td>    0.026</td> <td>   -0.091</td> <td> 0.927</td> <td>   -0.052</td> <td>    0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_min_avg</th>                    <td>   -0.0309</td> <td>    0.008</td> <td>   -3.809</td> <td> 0.000</td> <td>   -0.047</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_max_avg</th>                    <td>   -0.0747</td> <td>    0.024</td> <td>   -3.105</td> <td> 0.002</td> <td>   -0.122</td> <td>   -0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_avg_avg</th>                    <td>    0.3843</td> <td>    0.032</td> <td>   11.857</td> <td> 0.000</td> <td>    0.321</td> <td>    0.448</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>self_reference_min_shares</th>     <td>   -0.0513</td> <td>    0.009</td> <td>   -5.638</td> <td> 0.000</td> <td>   -0.069</td> <td>   -0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>self_reference_max_shares</th>     <td>   -0.2042</td> <td>    0.026</td> <td>   -7.979</td> <td> 0.000</td> <td>   -0.254</td> <td>   -0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>self_reference_avg_sharess</th>    <td>    0.2736</td> <td>    0.033</td> <td>    8.395</td> <td> 0.000</td> <td>    0.210</td> <td>    0.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weekday_is_monday</th>             <td>    0.5647</td> <td>    0.007</td> <td>   79.729</td> <td> 0.000</td> <td>    0.551</td> <td>    0.579</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weekday_is_tuesday</th>            <td>    0.5617</td> <td>    0.007</td> <td>   78.935</td> <td> 0.000</td> <td>    0.548</td> <td>    0.576</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weekday_is_wednesday</th>          <td>    0.5616</td> <td>    0.007</td> <td>   78.934</td> <td> 0.000</td> <td>    0.548</td> <td>    0.575</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weekday_is_thursday</th>           <td>    0.5620</td> <td>    0.007</td> <td>   79.030</td> <td> 0.000</td> <td>    0.548</td> <td>    0.576</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weekday_is_friday</th>             <td>    0.5653</td> <td>    0.007</td> <td>   79.396</td> <td> 0.000</td> <td>    0.551</td> <td>    0.579</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weekday_is_saturday</th>           <td>   -0.0001</td> <td>    0.001</td> <td>   -0.130</td> <td> 0.896</td> <td>   -0.002</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_weekend</th>                    <td>    0.5753</td> <td>    0.007</td> <td>   80.419</td> <td> 0.000</td> <td>    0.561</td> <td>    0.589</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LDA_01</th>                        <td>   -0.0141</td> <td>    0.002</td> <td>   -8.154</td> <td> 0.000</td> <td>   -0.018</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LDA_02</th>                        <td>   -0.0221</td> <td>    0.002</td> <td>  -13.520</td> <td> 0.000</td> <td>   -0.025</td> <td>   -0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LDA_03</th>                        <td>   -0.0135</td> <td>    0.002</td> <td>   -8.214</td> <td> 0.000</td> <td>   -0.017</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LDA_04</th>                        <td>   -0.0112</td> <td>    0.001</td> <td>   -7.470</td> <td> 0.000</td> <td>   -0.014</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>global_subjectivity</th>           <td>    0.0205</td> <td>    0.003</td> <td>    7.387</td> <td> 0.000</td> <td>    0.015</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>global_sentiment_polarity</th>     <td>   -0.0100</td> <td>    0.005</td> <td>   -1.831</td> <td> 0.067</td> <td>   -0.021</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>global_rate_positive_words</th>    <td>   -0.0244</td> <td>    0.023</td> <td>   -1.043</td> <td> 0.297</td> <td>   -0.070</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>global_rate_negative_words</th>    <td>   -0.0029</td> <td>    0.045</td> <td>   -0.064</td> <td> 0.949</td> <td>   -0.090</td> <td>    0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rate_positive_words</th>           <td>    0.0307</td> <td>    0.010</td> <td>    3.118</td> <td> 0.002</td> <td>    0.011</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rate_negative_words</th>           <td>    0.0244</td> <td>    0.010</td> <td>    2.397</td> <td> 0.017</td> <td>    0.004</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_positive_polarity</th>         <td>    0.0007</td> <td>    0.004</td> <td>    0.163</td> <td> 0.871</td> <td>   -0.008</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>min_positive_polarity</th>         <td>   -0.0130</td> <td>    0.004</td> <td>   -3.422</td> <td> 0.001</td> <td>   -0.020</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_positive_polarity</th>         <td> 8.712e-05</td> <td>    0.001</td> <td>    0.061</td> <td> 0.952</td> <td>   -0.003</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_negative_polarity</th>         <td>   -0.0009</td> <td>    0.004</td> <td>   -0.217</td> <td> 0.828</td> <td>   -0.009</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>min_negative_polarity</th>         <td>   -0.0026</td> <td>    0.001</td> <td>   -1.735</td> <td> 0.083</td> <td>   -0.006</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_negative_polarity</th>         <td>    0.0023</td> <td>    0.003</td> <td>    0.655</td> <td> 0.512</td> <td>   -0.004</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>title_subjectivity</th>            <td>    0.0026</td> <td>    0.001</td> <td>    2.893</td> <td> 0.004</td> <td>    0.001</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>title_sentiment_polarity</th>      <td>    0.0034</td> <td>    0.001</td> <td>    4.108</td> <td> 0.000</td> <td>    0.002</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>abs_title_subjectivity</th>        <td>    0.0058</td> <td>    0.001</td> <td>    4.882</td> <td> 0.000</td> <td>    0.003</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>abs_title_sentiment_polarity</th>  <td>    0.0012</td> <td>    0.001</td> <td>    0.932</td> <td> 0.351</td> <td>   -0.001</td> <td>    0.004</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>4693.207</td> <th>  Durbin-Watson:     </th> <td>   1.931</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>22194.733</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.493</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 6.530</td>  <th>  Cond. No.          </th> <td>1.75e+03</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.75e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 shares   R-squared:                       0.120\n",
       "Model:                            OLS   Adj. R-squared:                  0.119\n",
       "Method:                 Least Squares   F-statistic:                     96.55\n",
       "Date:                Thu, 09 Nov 2023   Prob (F-statistic):               0.00\n",
       "Time:                        16:43:23   Log-Likelihood:                 73840.\n",
       "No. Observations:               39644   AIC:                        -1.476e+05\n",
       "Df Residuals:                   39587   BIC:                        -1.471e+05\n",
       "Df Model:                          56                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================================\n",
       "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------\n",
       "timedelta                         0.0038      0.004      0.884      0.377      -0.005       0.012\n",
       "n_tokens_title                    0.0279      0.011      2.474      0.013       0.006       0.050\n",
       "n_tokens_content                 -0.0972      0.017     -5.881      0.000      -0.130      -0.065\n",
       "n_unique_tokens                  -0.4513      0.087     -5.174      0.000      -0.622      -0.280\n",
       "n_non_stop_words                  0.2073      0.089      2.325      0.020       0.033       0.382\n",
       "n_non_stop_unique_tokens          0.1834      0.065      2.825      0.005       0.056       0.311\n",
       "num_hrefs                         0.0417      0.004     11.334      0.000       0.035       0.049\n",
       "num_self_hrefs                   -0.0270      0.004     -6.728      0.000      -0.035      -0.019\n",
       "num_imgs                          0.0199      0.002      9.051      0.000       0.016       0.024\n",
       "num_videos                        0.0270      0.002     10.850      0.000       0.022       0.032\n",
       "average_token_length             -0.0135      0.011     -1.279      0.201      -0.034       0.007\n",
       "num_keywords                      0.0642      0.010      6.457      0.000       0.045       0.084\n",
       "data_channel_is_lifestyle        -0.0057      0.001     -4.380      0.000      -0.008      -0.003\n",
       "data_channel_is_entertainment    -0.0121      0.001    -14.725      0.000      -0.014      -0.010\n",
       "data_channel_is_bus              -0.0106      0.001     -8.494      0.000      -0.013      -0.008\n",
       "data_channel_is_socmed            0.0053      0.001      4.356      0.000       0.003       0.008\n",
       "data_channel_is_tech              0.0017      0.001      1.438      0.150      -0.001       0.004\n",
       "data_channel_is_world            -0.0064      0.001     -5.236      0.000      -0.009      -0.004\n",
       "kw_min_min                        0.0031      0.002      1.628      0.104      -0.001       0.007\n",
       "kw_max_min                        0.0110      0.003      4.188      0.000       0.006       0.016\n",
       "kw_avg_min                       -0.0061      0.004     -1.676      0.094      -0.013       0.001\n",
       "kw_min_max                        0.0262      0.008      3.473      0.001       0.011       0.041\n",
       "kw_max_max                       -0.1836      0.023     -7.838      0.000      -0.230      -0.138\n",
       "kw_avg_max                       -0.0023      0.026     -0.091      0.927      -0.052       0.048\n",
       "kw_min_avg                       -0.0309      0.008     -3.809      0.000      -0.047      -0.015\n",
       "kw_max_avg                       -0.0747      0.024     -3.105      0.002      -0.122      -0.028\n",
       "kw_avg_avg                        0.3843      0.032     11.857      0.000       0.321       0.448\n",
       "self_reference_min_shares        -0.0513      0.009     -5.638      0.000      -0.069      -0.033\n",
       "self_reference_max_shares        -0.2042      0.026     -7.979      0.000      -0.254      -0.154\n",
       "self_reference_avg_sharess        0.2736      0.033      8.395      0.000       0.210       0.337\n",
       "weekday_is_monday                 0.5647      0.007     79.729      0.000       0.551       0.579\n",
       "weekday_is_tuesday                0.5617      0.007     78.935      0.000       0.548       0.576\n",
       "weekday_is_wednesday              0.5616      0.007     78.934      0.000       0.548       0.575\n",
       "weekday_is_thursday               0.5620      0.007     79.030      0.000       0.548       0.576\n",
       "weekday_is_friday                 0.5653      0.007     79.396      0.000       0.551       0.579\n",
       "weekday_is_saturday              -0.0001      0.001     -0.130      0.896      -0.002       0.002\n",
       "is_weekend                        0.5753      0.007     80.419      0.000       0.561       0.589\n",
       "LDA_01                           -0.0141      0.002     -8.154      0.000      -0.018      -0.011\n",
       "LDA_02                           -0.0221      0.002    -13.520      0.000      -0.025      -0.019\n",
       "LDA_03                           -0.0135      0.002     -8.214      0.000      -0.017      -0.010\n",
       "LDA_04                           -0.0112      0.001     -7.470      0.000      -0.014      -0.008\n",
       "global_subjectivity               0.0205      0.003      7.387      0.000       0.015       0.026\n",
       "global_sentiment_polarity        -0.0100      0.005     -1.831      0.067      -0.021       0.001\n",
       "global_rate_positive_words       -0.0244      0.023     -1.043      0.297      -0.070       0.022\n",
       "global_rate_negative_words       -0.0029      0.045     -0.064      0.949      -0.090       0.085\n",
       "rate_positive_words               0.0307      0.010      3.118      0.002       0.011       0.050\n",
       "rate_negative_words               0.0244      0.010      2.397      0.017       0.004       0.044\n",
       "avg_positive_polarity             0.0007      0.004      0.163      0.871      -0.008       0.009\n",
       "min_positive_polarity            -0.0130      0.004     -3.422      0.001      -0.020      -0.006\n",
       "max_positive_polarity          8.712e-05      0.001      0.061      0.952      -0.003       0.003\n",
       "avg_negative_polarity            -0.0009      0.004     -0.217      0.828      -0.009       0.007\n",
       "min_negative_polarity            -0.0026      0.001     -1.735      0.083      -0.006       0.000\n",
       "max_negative_polarity             0.0023      0.003      0.655      0.512      -0.004       0.009\n",
       "title_subjectivity                0.0026      0.001      2.893      0.004       0.001       0.004\n",
       "title_sentiment_polarity          0.0034      0.001      4.108      0.000       0.002       0.005\n",
       "abs_title_subjectivity            0.0058      0.001      4.882      0.000       0.003       0.008\n",
       "abs_title_sentiment_polarity      0.0012      0.001      0.932      0.351      -0.001       0.004\n",
       "==============================================================================\n",
       "Omnibus:                     4693.207   Durbin-Watson:                   1.931\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            22194.733\n",
       "Skew:                           0.493   Prob(JB):                         0.00\n",
       "Kurtosis:                       6.530   Cond. No.                     1.75e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.75e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = sm.OLS(news_response, news_trimmed_features).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42edd6c",
   "metadata": {},
   "source": [
    "- **Df Model = 56:** Independent elements in the model parameters. 57 columns, but last is fixed by the need to minimize the remaning error, so there are only 56 **degrees of freedom** overall.  \n",
    "- **Df Residuals = 39587:** Number od independent pieces of information in the error estimates of the model. Recall, we obtain the errors by $y-X$. We only have up to $m$ ind.cols in $X$, where $m$ is the number of predictors. SO the estimate of the error has $n-1$ ind. elements, from which we substract another $m$ which is determined by the inputs, giving us $n-m-1$. \n",
    "- **Covariance Type = nonrobust:** Here we use **white noise** (a mean 0, normally distributed error), is possible to specified this type. i.e where tje error is correlated with the magnitude of the response.\n",
    "- **Adj. R-squared = 0.119:** For models with larger numbers of parameters, we penaize the R2 by the amount of errir in the fit. This indicator is if we include more variables in a model, the $R^2$ increase ny simply having more Df. If we wish to fairly compare the $R^2$ for models with different numbers of parameters, then we use the formula of $R^{2}_{adj}$.  \n",
    "- **F-statistic = 96.55:** Is used to compare (through a Chi-squared dist.) that any (cualquiera) of the regression coefficients are statistically different than $0$.\n",
    "- **Prob (F-statistic) = 0.00:** The p-value (from the F-statistic), proves that the null hypothesis (that the coeff. are $0$ and the fit is no better than the intercept-only model) is true. \n",
    "- **Log-Likelihood = 73840.0:** Recall that we assume the error of the residuals in the linear model is normally distributed. To determine how well fits this assumptions, we can coompute with its own function. It can helps us to compare two models (i.e with different coeff.) Better goodness of fit is represented by a larger log likelihood. or a lower negative log likelihood.\n",
    "<br>\n",
    "\n",
    "> In practice, is better to minimize the (-) log likelihood instead of maximizing. In this project assume minimization as the default objective.  \n",
    "\n",
    "- **AIC = -1.476e+05 / BIC = -1.471e+05:** Stands for Akaike Information Criterion and Bayes Information Criterion. These help to compare models with different numbers of coefficients, thus gibing a sense of benefit of greater model complexity from addign more features.  \n",
    "> AIC = $2m - 2\\log(L(\\beta))$: m is the number of coeff in the model and L is the likelihood. Better goodness of fit is represented by lower AIC. Thus, increasing the number of parameters penalizes the model, while improving the likelihood that it decreases the AIC. BIC is similar, but uses the formula $-2L(\\beta) + \\log(n)$. When n is the number of data points in the model.  \n",
    "\n",
    ">So, If AIC has the lowest value for a corresponding model, it indicates a better fit compared to other models. In the same way if in the evaluation one model has the lowest BIC value, that indicates a better fit compared to other models.  \n",
    "\n",
    "- **Durbin-Watson = 1.931:** This statistic asks whether the residuals are positively or negatively correlated. If its value is >2, this suggests a positive correlation. Values between 1 and 2 indicate little to correlation, with 2 indicating no correlation. Values less than 1 represent negative correlation between successive residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80885857",
   "metadata": {},
   "source": [
    "**FORMULA.API METHOD**  \n",
    "By constructing a string from the input data representing the formula for the linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "daca52ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_formula = news_response.name+\" ~ \"+\" + \".join(news_trimmed_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3d975d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shares ~ timedelta + n_tokens_title + n_tokens_content + n_unique_tokens + n_non_stop_words + n_non_stop_unique_tokens + num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + num_keywords + data_channel_is_lifestyle + data_channel_is_entertainment + data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + data_channel_is_world + kw_min_min + kw_max_min + kw_avg_min + kw_min_max + kw_max_max + kw_avg_max + kw_min_avg + kw_max_avg + kw_avg_avg + self_reference_min_shares + self_reference_max_shares + self_reference_avg_sharess + weekday_is_monday + weekday_is_tuesday + weekday_is_wednesday + weekday_is_thursday + weekday_is_friday + weekday_is_saturday + is_weekend + LDA_01 + LDA_02 + LDA_03 + LDA_04 + global_subjectivity + global_sentiment_polarity + global_rate_positive_words + global_rate_negative_words + rate_positive_words + rate_negative_words + avg_positive_polarity + min_positive_polarity + max_positive_polarity + avg_negative_polarity + min_negative_polarity + max_negative_polarity + title_subjectivity + title_sentiment_polarity + abs_title_subjectivity + abs_title_sentiment_polarity'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9e1f2b",
   "metadata": {},
   "source": [
    "Also we can use pandas, and calling the ols method of the formula API we imported previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "79fd1096",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_all_data = pd.concat([news_trimmed_features,news_response],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "241eec16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.587095</td>\n",
       "      <td>0.325093</td>\n",
       "      <td>0.524061</td>\n",
       "      <td>0.086733</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.100015</td>\n",
       "      <td>0.230186</td>\n",
       "      <td>0.169416</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.576777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.587095</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.532530</td>\n",
       "      <td>0.081133</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.098064</td>\n",
       "      <td>0.204679</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.585740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.587095</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.521966</td>\n",
       "      <td>0.078209</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.086758</td>\n",
       "      <td>0.204679</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.587095</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.571233</td>\n",
       "      <td>0.070845</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.086922</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.610612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.587095</td>\n",
       "      <td>0.331656</td>\n",
       "      <td>0.605370</td>\n",
       "      <td>0.061058</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.074733</td>\n",
       "      <td>0.361922</td>\n",
       "      <td>0.361922</td>\n",
       "      <td>0.365903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.568689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39639</th>\n",
       "      <td>0.290978</td>\n",
       "      <td>0.317892</td>\n",
       "      <td>0.549044</td>\n",
       "      <td>0.073507</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.088683</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.279459</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.260000</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.628952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39640</th>\n",
       "      <td>0.290978</td>\n",
       "      <td>0.325093</td>\n",
       "      <td>0.546197</td>\n",
       "      <td>0.089729</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.105621</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.279459</td>\n",
       "      <td>0.204679</td>\n",
       "      <td>0.429784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.211111</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.631340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39641</th>\n",
       "      <td>0.290978</td>\n",
       "      <td>0.309927</td>\n",
       "      <td>0.561865</td>\n",
       "      <td>0.072177</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.084911</td>\n",
       "      <td>0.379838</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.325093</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.356439</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.631340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39642</th>\n",
       "      <td>0.290978</td>\n",
       "      <td>0.266019</td>\n",
       "      <td>0.583700</td>\n",
       "      <td>0.074589</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.309927</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.205246</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.012500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.606573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39643</th>\n",
       "      <td>0.290978</td>\n",
       "      <td>0.309927</td>\n",
       "      <td>0.504968</td>\n",
       "      <td>0.090243</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.102526</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.614294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39644 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "0       0.587095        0.325093          0.524061         0.086733   \n",
       "1       0.587095        0.301030          0.532530         0.081133   \n",
       "2       0.587095        0.301030          0.521966         0.078209   \n",
       "3       0.587095        0.301030          0.571233         0.070845   \n",
       "4       0.587095        0.331656          0.605370         0.061058   \n",
       "...          ...             ...               ...              ...   \n",
       "39639   0.290978        0.317892          0.549044         0.073507   \n",
       "39640   0.290978        0.325093          0.546197         0.089729   \n",
       "39641   0.290978        0.309927          0.561865         0.072177   \n",
       "39642   0.290978        0.266019          0.583700         0.074589   \n",
       "39643   0.290978        0.309927          0.504968         0.090243   \n",
       "\n",
       "       n_non_stop_words  n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  \\\n",
       "0              0.114287                  0.100015   0.230186        0.169416   \n",
       "1              0.114287                  0.098064   0.204679        0.114287   \n",
       "2              0.114287                  0.086758   0.204679        0.114287   \n",
       "3              0.114287                  0.086922   0.301030        0.000000   \n",
       "4              0.114287                  0.074733   0.361922        0.361922   \n",
       "...                 ...                       ...        ...             ...   \n",
       "39639          0.114287                  0.088683   0.301030        0.279459   \n",
       "39640          0.114287                  0.105621   0.301030        0.279459   \n",
       "39641          0.114287                  0.084911   0.379838        0.114287   \n",
       "39642          0.114287                  0.089400   0.309927        0.114287   \n",
       "39643          0.114287                  0.102526   0.114287        0.114287   \n",
       "\n",
       "       num_imgs  num_videos  ...  min_positive_polarity  \\\n",
       "0      0.114287    0.000000  ...               0.100000   \n",
       "1      0.114287    0.000000  ...               0.033333   \n",
       "2      0.114287    0.000000  ...               0.100000   \n",
       "3      0.114287    0.000000  ...               0.136364   \n",
       "4      0.365903    0.000000  ...               0.033333   \n",
       "...         ...         ...  ...                    ...   \n",
       "39639  0.114287    0.114287  ...               0.100000   \n",
       "39640  0.204679    0.429784  ...               0.136364   \n",
       "39641  0.325093    0.114287  ...               0.136364   \n",
       "39642  0.114287    0.000000  ...               0.062500   \n",
       "39643  0.000000    0.169416  ...               0.100000   \n",
       "\n",
       "       max_positive_polarity  avg_negative_polarity  min_negative_polarity  \\\n",
       "0                       0.70              -0.350000                 -0.600   \n",
       "1                       0.70              -0.118750                 -0.125   \n",
       "2                       1.00              -0.466667                 -0.800   \n",
       "3                       0.80              -0.369697                 -0.600   \n",
       "4                       1.00              -0.220192                 -0.500   \n",
       "...                      ...                    ...                    ...   \n",
       "39639                   0.75              -0.260000                 -0.500   \n",
       "39640                   0.70              -0.211111                 -0.400   \n",
       "39641                   0.50              -0.356439                 -0.800   \n",
       "39642                   0.50              -0.205246                 -0.500   \n",
       "39643                   0.50              -0.200000                 -0.200   \n",
       "\n",
       "       max_negative_polarity  title_subjectivity  title_sentiment_polarity  \\\n",
       "0                  -0.200000            0.500000                 -0.187500   \n",
       "1                  -0.100000            0.000000                  0.000000   \n",
       "2                  -0.133333            0.000000                  0.000000   \n",
       "3                  -0.166667            0.000000                  0.000000   \n",
       "4                  -0.050000            0.454545                  0.136364   \n",
       "...                      ...                 ...                       ...   \n",
       "39639              -0.125000            0.100000                  0.000000   \n",
       "39640              -0.100000            0.300000                  1.000000   \n",
       "39641              -0.166667            0.454545                  0.136364   \n",
       "39642              -0.012500            0.000000                  0.000000   \n",
       "39643              -0.200000            0.333333                  0.250000   \n",
       "\n",
       "       abs_title_subjectivity  abs_title_sentiment_polarity    shares  \n",
       "0                    0.000000                      0.187500  0.576777  \n",
       "1                    0.500000                      0.000000  0.585740  \n",
       "2                    0.500000                      0.000000  0.620800  \n",
       "3                    0.500000                      0.000000  0.610612  \n",
       "4                    0.045455                      0.136364  0.568689  \n",
       "...                       ...                           ...       ...  \n",
       "39639                0.400000                      0.000000  0.628952  \n",
       "39640                0.200000                      1.000000  0.631340  \n",
       "39641                0.045455                      0.136364  0.631340  \n",
       "39642                0.500000                      0.000000  0.606573  \n",
       "39643                0.166667                      0.250000  0.614294  \n",
       "\n",
       "[39644 rows x 58 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1890d98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = smf.ols(formula=model_formula,data=news_all_data).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5ca6d8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x13ccf6fd720>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76768fe6",
   "metadata": {},
   "source": [
    "In this example, it seems reasonable to assume that the residuals of the model we fit for popularity as a function of new item characteristics are independent. \n",
    "In other cases, we might make multiple observations on the same set of entries (as when a given customer appears more than once in a dataset), and these data might be correlated over time (as when records for the same customer are more likely to be correlated when they appear closer together in time). Both situations violate the assumptions of independence between the residuals of a model. In the following sections we will present three methods to deal with these cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa3a027",
   "metadata": {},
   "source": [
    "**GENERALIZE ESTIMATING EQUATIONS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb8c011",
   "metadata": {},
   "source": [
    "In the following series of exercises we will use an example of students' grades in a mathematics course in several schools recorded over three terms, expressed by the symbols (G1-3).  \n",
    "It is expected that there would be a correlation between the school in which they are enrolled and their mathematics grades in each term.  \n",
    "\n",
    "Some evidence of this will be seen when plotting the data using the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ec8098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6064fbbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b725ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18228a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0df26e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7739be1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
